{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# demo.ipynb\n",
        "\n",
        "# Logistic Regression from Scratch: Binary and Multiclass Demo\n",
        "\n",
        "##  Setup\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris, load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from logistic_binary import LogisticRegression_\n",
        "from logistic_multiclass import MultiClassLogisticRegression\n",
        "from utils import plot_decision_region\n",
        "from sklearn.linear_model import LogisticRegression as SklearnLogReg\n",
        "\n",
        "\n",
        "## Binary Logistic Regression Demo (Iris: Class 0 vs 1)\n",
        "\n",
        "iris = load_iris()\n",
        "class_01 = (iris.target == 0) | (iris.target == 1)\n",
        "X = iris.data[class_01][:, [0, 2]]  # Sepal length and petal length\n",
        "y = iris.target[class_01]\n",
        "\n",
        "# Shuffle and scale\n",
        "perm = np.random.permutation(len(X))\n",
        "X, y = X[perm], y[perm]\n",
        "X_scaled = (X - X.mean(axis=0)) / X.std(axis=0)\n",
        "\n",
        "model = LogisticRegression_(eta=0.01, n_iter=50)\n",
        "model.fit(X_scaled, y)\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plot_decision_region(X_scaled, y, model)\n",
        "plt.title(\"Binary Classification Decision Boundary\")\n",
        "plt.xlabel(\"Sepal Length (standardized)\")\n",
        "plt.ylabel(\"Petal Length (standardized)\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(model.losses_, marker='o')\n",
        "plt.title(\"Loss over Epochs\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Binary Cross-Entropy Loss\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "## Multiclass Logistic Regression vs Sklearn (Digits)\n",
        "\n",
        "digits = load_digits()\n",
        "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Custom implementation\n",
        "custom_model = MultiClassLogisticRegression(n_iter=500, eta=0.1, penalty='l2', early_stopping=10)\n",
        "custom_model.fit(X_train, y_train)\n",
        "custom_preds = custom_model.predict(X_test)\n",
        "\n",
        "# Sklearn for comparison\n",
        "sklearn_model = SklearnLogReg(max_iter=500, multi_class='ovr')\n",
        "sklearn_model.fit(X_train, y_train)\n",
        "sklearn_preds = sklearn_model.predict(X_test)\n",
        "\n",
        "# Accuracy Comparison\n",
        "custom_acc = accuracy_score(y_test, custom_preds)\n",
        "sklearn_acc = accuracy_score(y_test, sklearn_preds)\n",
        "\n",
        "print(f\"Sklearn Logistic Regression Accuracy: {sklearn_acc:.4f}\")\n",
        "print(f\"Custom Logistic Regression Accuracy: {custom_acc:.4f}\")\n",
        "\n",
        "## Plot Loss Curve for Custom Multiclass\n",
        "plt.plot(custom_model.losses_, marker='x')\n",
        "plt.title(\"Multiclass Logistic Regression Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Cross-Entropy Loss\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "hqL7dQ1rCa5X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}