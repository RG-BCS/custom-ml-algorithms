{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"script","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %% [code]\nimport numpy as np\nfrom sklearn.datasets import load_iris\nimport matplotlib.pyplot as plt\n\n# Implementing a Perceptron from scratch\n# Note: This model doesn't use a loss function in the traditional sense.\n# Weight updates are based on classification errors (no gradient descent with loss derivatives).\n\nclass Perceptron:\n    def __init__(self, eta=0.01, n_iter=50, random_state=1):\n        self.eta = eta                      # Learning rate\n        self.n_iter = n_iter                # Number of training epochs\n        self.random_state = random_state    # For reproducible weight initialization\n\n    def fit(self, X, y):\n        rng = np.random.RandomState(self.random_state)\n        self.w_ = rng.normal(loc=0.0, scale=0.01, size=X.shape[1])  # Weight initialization\n        # Alternative: self.w_ = np.zeros(X.shape[1])  # To test learning behavior from zero init\n        self.b_ = 0.0\n        self.errors_ = []\n\n        for epoch in range(self.n_iter):\n            errors = 0\n            for x_i, y_i in zip(X, y):\n                y_pred = self.predict(x_i)\n                error = y_i - y_pred\n                # Update rule\n                self.w_ += self.eta * error * x_i\n                self.b_ += self.eta * error\n                errors += int(error != 0)\n            self.errors_.append(errors)\n        return self\n\n    def net_input(self, x):\n        \"\"\"Calculate net input (weighted sum + bias).\"\"\"\n        return np.dot(x, self.w_) + self.b_\n\n    def predict(self, x):\n        \"\"\"Return class label after unit step.\"\"\"\n        return np.where(self.net_input(x) >= 0.0, 1, 0)\n\n    def __repr__(self):\n        return (f\"Perceptron(n_iter={self.n_iter}, eta={self.eta}, random_state={self.random_state})\")\n","metadata":{"_uuid":"e4f3179c-4b8e-4568-b41b-e64969063630","_cell_guid":"cb0e28da-5836-40dc-ad17-56a1e6d3eec9","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}