{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Title\n",
        "# Majority Vote Classifier Demo\n",
        "\n",
        "\"\"\"\n",
        "This notebook demonstrates a custom ensemble method: the MajorityVoteClassifier.\n",
        "It aggregates predictions from multiple classifiers using either class label or probability-based voting.\n",
        "\n",
        "We'll evaluate its performance using:\n",
        "- ROC AUC\n",
        "- Precision-Recall curves\n",
        "- Decision boundary plots\n",
        "\"\"\"\n",
        "\n",
        "# Cell 2: Imports\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
        "from majority_vote_classifier import MajorityVoteClassifier\n",
        "from utils import plot_decision_region\n",
        "\n",
        "# Cell 3: Data Preparation\n",
        "iris = load_iris()\n",
        "X, Y = iris.data[50:, [1, 2]], iris.target[50:]\n",
        "\n",
        "labelenc = LabelEncoder()\n",
        "y = labelenc.fit_transform(Y)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.5, stratify=y, random_state=1)\n",
        "\n",
        "# Cell 4: Classifier Setup\n",
        "clf1 = make_pipeline(StandardScaler(), LogisticRegression(C=0.001, solver='lbfgs', random_state=1))\n",
        "clf2 = DecisionTreeClassifier(max_depth=1, random_state=1, criterion='entropy')\n",
        "clf3 = make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=2, p=2, metric='minkowski'))\n",
        "\n",
        "classifiers = [clf1, clf2, clf3]\n",
        "clf_labels = ['Logistic Regression', 'Decision Tree', 'KNN']\n",
        "\n",
        "# Cell 5: Individual Classifier Performance\n",
        "print(\"10-fold Cross Validation (ROC AUC):\")\n",
        "for clf, label in zip(classifiers, clf_labels):\n",
        "    scores = cross_val_score(estimator=clf, X=x_train, y=y_train, cv=10, scoring='roc_auc')\n",
        "    print(f\"{label}: ROC AUC = {scores.mean():.2f} (+/- {scores.std():.2f})\")\n",
        "\n",
        "# Cell 6: Majority Voting\n",
        "mv_clf = MajorityVoteClassifier(classifiers=classifiers)\n",
        "clf_labels.append(\"Majority Voting\")\n",
        "classifiers_mv = classifiers + [mv_clf]\n",
        "\n",
        "print(\"\\nWith Majority Voting Added:\")\n",
        "for clf, label in zip(classifiers_mv, clf_labels):\n",
        "    scores = cross_val_score(estimator=clf, X=x_train, y=y_train, cv=10, scoring='roc_auc')\n",
        "    print(f\"{label}: ROC AUC = {scores.mean():.2f} (+/- {scores.std():.2f})\")\n",
        "\n",
        "# Cell 7: ROC Curve\n",
        "colors = ['black', 'orange', 'blue', 'green']\n",
        "linestyles = [':', '--', '-.', '-']\n",
        "plt.figure(figsize=(6, 6))\n",
        "\n",
        "for clf, label, clr, ls in zip(classifiers_mv, clf_labels, colors, linestyles):\n",
        "    clf.fit(x_train, y_train)\n",
        "    y_prob = clf.predict_proba(x_test)[:, 1]\n",
        "    fpr, tpr, _ = roc_curve(y_true=y_test, y_score=y_prob)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.plot(fpr, tpr, label=f'{label} (AUC = {roc_auc:.2f})', linestyle=ls, color=clr)\n",
        "\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve on Test Set')\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.5)\n",
        "plt.show()\n",
        "\n",
        "# Cell 8: Precision-Recall Curve\n",
        "plt.figure(figsize=(6, 6))\n",
        "\n",
        "for clf, label, clr, ls in zip(classifiers_mv, clf_labels, colors, linestyles):\n",
        "    clf.fit(x_train, y_train)\n",
        "    y_prob = clf.predict_proba(x_test)[:, 1]\n",
        "    precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
        "    pr_auc = auc(recall, precision)\n",
        "    plt.plot(recall, precision, label=f'{label} (AUC = {pr_auc:.2f})', linestyle=ls, color=clr)\n",
        "\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve on Test Set')\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.5)\n",
        "plt.show()\n",
        "\n",
        "# Cell 9: Decision Regions\n",
        "plt.figure(figsize=(10, 8))\n",
        "for idx, (clf, label) in enumerate(zip(classifiers_mv, clf_labels)):\n",
        "    clf.fit(x_train, y_train)\n",
        "    plt.subplot(2, 2, idx + 1)\n",
        "    plot_decision_region(x_train, y_train, clf)\n",
        "    plt.title(label)\n",
        "    plt.tight_layout()\n",
        "\n",
        "plt.suptitle(\"Decision Regions\", fontsize=14, y=1.02)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ABtsuIMlgwkt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}